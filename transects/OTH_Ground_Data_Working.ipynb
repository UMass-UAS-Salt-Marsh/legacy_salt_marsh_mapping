{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries / Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtCore import *\n",
    "import pandas as pd\n",
    "from qgis.core import *\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "import sys\n",
    "import math\n",
    "import numpy\n",
    "from shapely.geometry import shape\n",
    "from shapely.geometry import Polygon\n",
    "from rtree import index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Increase width of notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to be used in script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to check for transect numbers of before and after points\n",
    "\n",
    "def transectCheck(rownumber, dataframe):\n",
    "    current = dataframe['Transect'].iloc[rownumber]\n",
    "    after = dataframe['Transect'].iloc[rownumber + 1]\n",
    "    if \"/\" in current:\n",
    "        slash1 = current.find(\"/\")\n",
    "        slash2 = slash1 + 1\n",
    "        current = current[slash2:]\n",
    "    else: pass\n",
    "    if \"/\" in after:\n",
    "        slash = after.find(\"/\")\n",
    "        after = after[:slash]\n",
    "\n",
    "    else: pass\n",
    "    \n",
    "    if current == after:\n",
    "        return 1\n",
    "    else: return 0\n",
    "    \n",
    "    \n",
    "# Create function to determine if a point is a mapping unit\n",
    "\n",
    "def muCheck(rownumber, dataframe):\n",
    "    # Check transects\n",
    "    currentT = dataframe['Transect'].iloc[rownumber]\n",
    "    currentT2 = dataframe['Transect'].iloc[rownumber]    \n",
    "    beforeT = dataframe['Transect'].iloc[rownumber - 1]\n",
    "    afterT = dataframe['Transect'].iloc[rownumber + 1]\n",
    "    if \"/\" in currentT:\n",
    "        slash1 = currentT.find(\"/\")\n",
    "        slash2 = slash1 + 1\n",
    "        currentT = currentT[slash2:]\n",
    "        currentT2 = currentT2[:slash1]\n",
    "    else: pass\n",
    "    if \"/\" in afterT:\n",
    "        slash = afterT.find(\"/\")\n",
    "        afterT = afterT[:slash]\n",
    "    else: pass\n",
    "    if \"/\" in beforeT:\n",
    "        slash3 = beforeT.find(\"/\")\n",
    "        slash4 = slash3 + 1\n",
    "        beforeT = beforeT[slash4:]\n",
    "    else: pass\n",
    "    \n",
    "    # Check subclasses\n",
    "    currentS = dataframe['Subclass'].iloc[rownumber][:2]\n",
    "    beforeS = dataframe['Subclass'].iloc[rownumber - 1][:2]\n",
    "    afterS = dataframe['Subclass'].iloc[rownumber + 1][:2]\n",
    "\n",
    "    if currentT == afterT and currentS == afterS: pass\n",
    "    else:\n",
    "            if currentT2 == beforeT and currentS == beforeS: pass\n",
    "            else: return 2\n",
    "            \n",
    "\n",
    "# Create function to determine if a point is a mapping unit for data with no transect field\n",
    "            \n",
    "def muCheckNoT(rownumber, dataframe):    \n",
    "    # Check subclasses\n",
    "    currentS = dataframe['Subclass'].iloc[rownumber][:2]\n",
    "    beforeS = dataframe['Subclass'].iloc[rownumber - 1][:2]\n",
    "    afterS = dataframe['Subclass'].iloc[rownumber + 1][:2]\n",
    "    \n",
    "    if currentS == afterS: pass\n",
    "    else:\n",
    "        if currentS == beforeS: pass\n",
    "        else: return 2\n",
    "            \n",
    "def muCheckLast(rownumber, dataframe):\n",
    "    # Check final subclass with [-1] subclass only\n",
    "    currentS = dataframe['Subclass'].iloc[rownumber][:2]\n",
    "    beforeS = dataframe['Subclass'].iloc[rownumber - 1][:2]\n",
    "    \n",
    "    if currentS == beforeS: pass\n",
    "    else: return 2\n",
    "    \n",
    "    \n",
    "# Define function to test whether angle of mu corresponds to pre or post angle\n",
    "\n",
    "def prepostCheck(rownumber, dataframe):\n",
    "    currentT = dataframe['Transect'].iloc[rownumber]\n",
    "    afterT = dataframe['Transect'].iloc[rownumber + 1]\n",
    "    \n",
    "    if \"/\" in currentT:\n",
    "        slash1 = currentT.find(\"/\")\n",
    "        slash2 = slash1 + 1\n",
    "        currentT = currentT[slash2:]\n",
    "    else: pass\n",
    "    \n",
    "    if \"/\" in afterT:\n",
    "        slash = afterT.find(\"/\")\n",
    "        afterT = afterT[:slash]\n",
    "    else: pass\n",
    "    \n",
    "    if currentT == afterT: return \"post\"\n",
    "    else: return \"pre\"\n",
    "    \n",
    "    \n",
    "def prepostCheckNoT(rownumber, dataframe):\n",
    "    # Check subclasses\n",
    "    currentS = dataframe['Subclass'].iloc[rownumber][:2]\n",
    "    beforeS = dataframe['Subclass'].iloc[rownumber - 1][:2]\n",
    "    afterS = dataframe['Subclass'].iloc[rownumber + 1][:2]\n",
    "    \n",
    "    if currentS == afterS: return \"post:\"\n",
    "    else: return \"pre\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Up the Data - Specify correct folders to be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter file path to site folder in EPA Salt Marsh UAS Study with quotations -- \"G:\\.shortcut-targets-by-id\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\SaltMUAS_share\\EPA Salt Marsh UAS Study\\Newbury\"\n"
     ]
    }
   ],
   "source": [
    "# Create directories within selected folder\n",
    "root = input(\"Enter file path to site folder in EPA Salt Marsh UAS Study with quotations -- \")\n",
    "root = root[1:-1]\n",
    "base = root + \"\\Jupyter_Working_Folder\"\n",
    "XY_Points_Folder = base + \"\\XY_Points\"\n",
    "Lines_Folder = base + \"\\Lines\"\n",
    "Buffer_Folder = base + \"\\Lines_Buffered\"\n",
    "Class_Lines_Folder = base + \"\\Class_Lines\"\n",
    "Class_Buffer_Folder = base + \"\\Class_Lines_Buffered\"\n",
    "mu_Folder = base + \"\\mu\"\n",
    "mu_Buffer_Folder = base + \"\\mu_Buffered\"\n",
    "working = base + \"\\working\"\n",
    "Polygon_Folder = base + \"\\Polygons\"\n",
    "folderList = [XY_Points_Folder, Lines_Folder, Buffer_Folder, mu_Folder, mu_Buffer_Folder, \n",
    "              Class_Lines_Folder, Class_Buffer_Folder, working, Polygon_Folder]\n",
    "for i in folderList:\n",
    "    if not os.path.exists(i):\n",
    "        os.makedirs(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check data to edit cell below to determine number of rows to exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter file path to ground truthing data .csv here -- \"G:\\.shortcut-targets-by-id\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\SaltMUAS_share\\EPA Salt Marsh UAS Study\\Newbury\\Ground Truthing\\NAD83_UTM19N\\oldtownhill14oct2018.csv\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RTCM0042</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>4747306.228</th>\n",
       "      <th>345583.160</th>\n",
       "      <th>16.646</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22r</td>\n",
       "      <td>4737159.533</td>\n",
       "      <td>347668.963</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22r</td>\n",
       "      <td>4737157.980</td>\n",
       "      <td>347669.880</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>22r</td>\n",
       "      <td>4737157.053</td>\n",
       "      <td>347671.442</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>22r</td>\n",
       "      <td>4737155.156</td>\n",
       "      <td>347673.739</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>22r</td>\n",
       "      <td>4737151.725</td>\n",
       "      <td>347671.306</td>\n",
       "      <td>0.342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RTCM0042 Unnamed: 1  4747306.228  345583.160  16.646\n",
       "0         1        22r  4737159.533  347668.963   0.695\n",
       "1         2        22r  4737157.980  347669.880   0.726\n",
       "2         3        22r  4737157.053  347671.442   0.785\n",
       "3         4        22r  4737155.156  347673.739   0.976\n",
       "4         5        22r  4737151.725  347671.306   0.342"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in .cvs with Transects\n",
    "# Keep quotations around file path in the input\n",
    "read_data = input(\"Enter file path to ground truthing data .csv here -- \")\n",
    "read_data = read_data[1:-1]\n",
    "\n",
    "# skiprows argument may need to be tweaked depending on format of the .csv's headers\n",
    "df = pd.read_csv(read_data, skiprows=1)\n",
    "# Observe number of rows to discard including RTC data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete top row with projection/datum and RTC data\n",
    "# datos = df.iloc[1:]\n",
    "# # Creating data frame\n",
    "dato = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column headers\n",
    "dato.columns = ['Point Number', 'Subclass', 'Northing', 'Easting', 'Altitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run this section if dealing with transect field\n",
    "# # Filter for null values where Transect != NaN \n",
    "# filter_dato = dato[dato['Transect'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you did not run the previous cell\n",
    "# Assign to filter_dato to not mess with remaining code\n",
    "filter_dato = dato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Point Number</th>\n",
       "      <th>Subclass</th>\n",
       "      <th>Northing</th>\n",
       "      <th>Easting</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Pre Angle</th>\n",
       "      <th>Post Angle</th>\n",
       "      <th>Class</th>\n",
       "      <th>mu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22r</td>\n",
       "      <td>4737159.533</td>\n",
       "      <td>347668.963</td>\n",
       "      <td>0.695</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22r</td>\n",
       "      <td>4737157.980</td>\n",
       "      <td>347669.880</td>\n",
       "      <td>0.726</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>22r</td>\n",
       "      <td>4737157.053</td>\n",
       "      <td>347671.442</td>\n",
       "      <td>0.785</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>22r</td>\n",
       "      <td>4737155.156</td>\n",
       "      <td>347673.739</td>\n",
       "      <td>0.976</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>22r</td>\n",
       "      <td>4737151.725</td>\n",
       "      <td>347671.306</td>\n",
       "      <td>0.342</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Point Number Subclass     Northing     Easting  Altitude Pre Angle  \\\n",
       "0             1      22r  4737159.533  347668.963     0.695             \n",
       "1             2      22r  4737157.980  347669.880     0.726             \n",
       "2             3      22r  4737157.053  347671.442     0.785             \n",
       "3             4      22r  4737155.156  347673.739     0.976             \n",
       "4             5      22r  4737151.725  347671.306     0.342             \n",
       "\n",
       "  Post Angle Class mu  \n",
       "0                      \n",
       "1                      \n",
       "2                      \n",
       "3                      \n",
       "4                      "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create empty fields for transect angles, Class, and mapping unit\n",
    "\n",
    "filter_dato['Pre Angle'] = \"\"\n",
    "filter_dato['Post Angle'] = \"\"\n",
    "filter_dato['Class'] = \"\"\n",
    "filter_dato['mu'] = \"\"\n",
    "\n",
    "# Preview the data\n",
    "filter_dato.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables of lists of coordinates of current, before, and after coordinates\n",
    "# This will be used to calculate angle from one point to the next\n",
    "\n",
    "y = 0\n",
    "precoordN = []\n",
    "for x in filter_dato.iterrows():\n",
    "    precoordN.append(filter_dato['Northing'].iloc[y-1])\n",
    "    y += 1\n",
    "y = 0\n",
    "precoordE = []\n",
    "for x in filter_dato.iterrows():\n",
    "    precoordE.append(filter_dato['Easting'].iloc[y-1])\n",
    "    y += 1\n",
    "y = 0\n",
    "currcoordN = []\n",
    "for x in filter_dato.iterrows():\n",
    "    currcoordN.append(filter_dato['Northing'].iloc[y])\n",
    "    y += 1\n",
    "y = 0\n",
    "currcoordE = []\n",
    "for x in filter_dato.iterrows():\n",
    "    currcoordE.append(filter_dato['Easting'].iloc[y])\n",
    "    y += 1\n",
    "y = 0\n",
    "postcoordN = []\n",
    "for x in filter_dato.iterrows():\n",
    "    if y+1 < len(filter_dato):\n",
    "        postcoordN.append(filter_dato['Northing'].iloc[y+1])\n",
    "        y += 1\n",
    "    else: break\n",
    "y = 0\n",
    "postcoordE = []\n",
    "for x in filter_dato.iterrows():\n",
    "    if y+1 < len(filter_dato):\n",
    "        postcoordE.append(filter_dato['Easting'].iloc[y+1])\n",
    "        y += 1\n",
    "    else: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append calculated angles to lists\n",
    "y = 0\n",
    "preAngle = []\n",
    "for i in filter_dato.iterrows():\n",
    "    if y-1 < 0:\n",
    "        preAngle.append(0)\n",
    "        y += 1\n",
    "    else:\n",
    "        myradians = math.atan2(currcoordN[y]-precoordN[y], currcoordE[y]-precoordE[y])\n",
    "        mydegrees = math.degrees(myradians)\n",
    "        preAngle.append(mydegrees)\n",
    "        y += 1\n",
    "\n",
    "y = 0\n",
    "postAngle = []\n",
    "for i in filter_dato.iterrows():\n",
    "    if y+1 < len(filter_dato):\n",
    "        myradians = math.atan2(postcoordN[y]-currcoordN[y], postcoordE[y]-currcoordE[y])\n",
    "        mydegrees = math.degrees(myradians)\n",
    "        postAngle.append(mydegrees)\n",
    "        y += 1\n",
    "    else: \n",
    "        postAngle.append(0)\n",
    "        y += 1       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse out Class from Subclass and append to new list\n",
    "\n",
    "classe = []\n",
    "y = 0\n",
    "for i in filter_dato.iterrows():\n",
    "    if filter_dato['Subclass'].iloc[y][:1] == \"0\" or filter_dato['Subclass'].iloc[y][:1] == \"1\":\n",
    "        classe.append(1)\n",
    "        y += 1\n",
    "    elif filter_dato['Subclass'].iloc[y][:1] == \"2\":\n",
    "        classe.append(2)\n",
    "        y += 1\n",
    "    elif filter_dato['Subclass'].iloc[y][:1] == \"3\":\n",
    "        classe.append(3)\n",
    "        y += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add lists to empty columns\n",
    "\n",
    "filter_dato['Pre Angle'] = preAngle\n",
    "filter_dato['Post Angle'] = postAngle\n",
    "filter_dato['Class'] = classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new shapefile for Points that do not create a line\n",
    "y = 0\n",
    "muList = []\n",
    "\n",
    "# for loop to write point for every mapping unit\n",
    "for feat in filter_dato.iterrows():\n",
    "    # Create if statement so you y is never > the length of your data set; this will end your script\n",
    "    if y + 1 < len(filter_dato):\n",
    "        if muCheckNoT(y, filter_dato) == 2:\n",
    "            muList.append(1)\n",
    "            \n",
    "            \n",
    "\n",
    "            y += 1\n",
    "        else: \n",
    "            muList.append(0)\n",
    "            y += 1\n",
    "    else:\n",
    "        if muCheckLast(y, filter_dato) == 2: muList.append(1)\n",
    "        else: muList.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append muList to dataframe\n",
    "filter_dato['mu'] = muList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column in dataframe to signify if the mu uses the pre or post angle\n",
    "filter_dato[\"Pre/Post\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create for loop to create list of pre or post to append to dataframe\n",
    "\n",
    "y = 0\n",
    "prepost = []\n",
    "\n",
    "for i in filter_dato.iterrows():\n",
    "    if y + 1 < len(filter_dato):\n",
    "        pp = prepostCheckNoT(y, filter_dato)\n",
    "        prepost.append(pp)\n",
    "        y += 1\n",
    "    else: prepost.append(\"pre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append prepost list to dataframe\n",
    "\n",
    "filter_dato[\"Pre/Post\"] = prepost\n",
    "\n",
    "filter_dato2 = filter_dato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterFilter = filter_dato2.loc[filter_dato2['Class'] == 2]\n",
    "filter_dato = filter_dato.loc[filter_dato['Class'] != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create QGIS XY Point Data into a List based on coordinates\n",
    "point_list = [QgsPointXY(r['Easting'], r['Northing']) for i, r in filter_dato.iterrows() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Multipoint list\n",
    "points = QgsGeometry.fromMultiPointXY(point_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the XY Point Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create fields with correct data types\n",
    "\n",
    "layerFields = QgsFields()\n",
    "layerFields.append(QgsField('PointNum', QVariant.Int))\n",
    "layerFields.append(QgsField('SubClass', QVariant.String))\n",
    "layerFields.append(QgsField('Northing', QVariant.Double))\n",
    "layerFields.append(QgsField('Easting', QVariant.Double))\n",
    "layerFields.append(QgsField('Altitude', QVariant.Double))\n",
    "layerFields.append(QgsField('Pre Angle', QVariant.Double))\n",
    "layerFields.append(QgsField('Post Angle', QVariant.Double))\n",
    "layerFields.append(QgsField('Class', QVariant.Int))\n",
    "layerFields.append(QgsField('mu', QVariant.Int))\n",
    "layerFields.append(QgsField('Pre/Post', QVariant.String))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write XY Point Data for each row in .csv\n",
    "\n",
    "# Specify output to variable\n",
    "XY_Output_Path = XY_Points_Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brett\\anaconda3\\envs\\CAFE\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: QgsVectorFileWriter constructor is deprecated\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Use for loop to create shapefile\n",
    "y = 0\n",
    "for x in filter_dato.itertuples():\n",
    "    # Specify file output and name of .shp\n",
    "    file = XY_Output_Path + \"\\XYPoint\" + str(y) + \".shp\"\n",
    "    # Set type (QgsWkbTypes.), CRS (EPSG:26919), and type of file (ESRI Shapefile)\n",
    "    writer = QgsVectorFileWriter(file, 'UTF-8', layerFields, QgsWkbTypes.MultiPoint, QgsCoordinateReferenceSystem('EPSG:26919'), 'ESRI Shapefile')\n",
    "    # Appends X and Y coordinates to variable 'point1' at the y position (starts at 0 and adds 1 for each iteration of the for loop)\n",
    "    point1 = QgsGeometry.fromPointXY(point_list[y])\n",
    "    # Create an empty feature\n",
    "    feat = QgsFeature()\n",
    "    # Set feature's geometry to that of point1\n",
    "    feat.setGeometry(point1)\n",
    "    # Set values from dataframe to attributes\n",
    "    # Values will be applied in the order you created the layerFields\n",
    "    feat.setAttributes([int(filter_dato['Point Number'].iloc[y]), \\\n",
    "                        filter_dato['Subclass'].iloc[y], filter_dato['Northing'].iloc[y].item(), \\\n",
    "                        filter_dato['Easting'].iloc[y].item(), filter_dato['Altitude'].iloc[y].item(), \\\n",
    "                        filter_dato['Pre Angle'].iloc[y].item(), \\\n",
    "                        filter_dato['Post Angle'].iloc[y].item(), filter_dato['Class'].iloc[y].item(), \\\n",
    "                        filter_dato['mu'].iloc[y].item(), filter_dato['Pre/Post'].iloc[y]])\n",
    "    # Add 1 to y to continue through the dataframe during next for loop\n",
    "    y += 1\n",
    "    # write the feature\n",
    "    writer.addFeature(feat)\n",
    "\n",
    "del(writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate all XY Point shapefiles into a single shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which folder to look in\n",
    "file = os.listdir(XY_Output_Path)\n",
    "\n",
    "# Look for all files ending in \".shp\"\n",
    "path = [os.path.join(XY_Output_Path, i) for i in file if \".shp\" in i]\n",
    "\n",
    "# Concatenate to file specified in last line of code\n",
    "gdf = gpd.GeoDataFrame(pd.concat([gpd.read_file(i) for i in path],\n",
    "                        ignore_index=True), crs=gpd.read_file(path[0]).crs)\n",
    "# Write to same folder + name of new folder to be created which will include the shapefile of compiled XY Points\n",
    "XY_Points_Comp = \"\\XY_Points_Comp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write concatenated files to output path\n",
    "gdf.to_file(XY_Output_Path + XY_Points_Comp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort shapefile by Point Number attribute\n",
    "# Assign XY_Points__Outfile to where the sorted compiled XY Points will be saved\n",
    "XY_Points_outfile = XY_Output_Path + XY_Points_Comp + \"\\\\XY_Points_Comp_Sort.shp\"\n",
    "# Designate which compiled shapefile will be sorted\n",
    "filePath = XY_Output_Path + XY_Points_Comp + XY_Points_Comp + \".shp\"\n",
    "# Use geopandas to read in shapefile - Append read shapefile to variable 'shape'\n",
    "shape = gpd.read_file(filePath)\n",
    "# Sort based on Point Number\n",
    "shape_sort = shape.iloc[shape['PointNum'].sort_values().index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-write file back out as sorted compiled shapefile\n",
    "shape_sort.to_file(driver = 'ESRI Shapefile', filename = XY_Points_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G:\\\\.shortcut-targets-by-id\\\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\\\SaltMUAS_share\\\\EPA Salt Marsh UAS Study\\\\Newbury\\\\Jupyter_Working_Folder\\\\XY_Points\\\\XY_Points_Comp\\\\XY_Points_Comp_Sort.shp'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY_Points_outfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create PolyLine Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify empty folder to put the Line files in\n",
    "linesFolder = Lines_Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create function to determine if a point is a mapping unit\n",
    "\n",
    "# def muCheck(rownumber, dataframe):\n",
    "#     # Check transects\n",
    "#     currentT = dataframe['Transect'].iloc[rownumber]\n",
    "#     currentT2 = dataframe['Transect'].iloc[rownumber]    \n",
    "#     beforeT = dataframe['Transect'].iloc[rownumber - 1]\n",
    "#     afterT = dataframe['Transect'].iloc[rownumber + 1]\n",
    "#     if \"/\" in currentT:\n",
    "#         slash1 = currentT.find(\"/\")\n",
    "#         slash2 = slash1 + 1\n",
    "#         currentT = currentT[slash2:]\n",
    "#         currentT2 = currentT2[:slash1]\n",
    "#     else: pass\n",
    "#     if \"/\" in afterT:\n",
    "#         slash = afterT.find(\"/\")\n",
    "#         afterT = afterT[:slash]\n",
    "#     else: pass\n",
    "#     if \"/\" in beforeT:\n",
    "#         slash3 = beforeT.find(\"/\")\n",
    "#         slash4 = slash3 + 1\n",
    "#         beforeT = beforeT[slash4:]\n",
    "#     else: pass\n",
    "    \n",
    "#     # Check subclasses\n",
    "#     currentS = dataframe['Subclass'].iloc[rownumber][:2]\n",
    "#     beforeS = dataframe['Subclass'].iloc[rownumber - 1][:2]\n",
    "#     afterS = dataframe['Subclass'].iloc[rownumber + 1][:2]\n",
    "\n",
    "#     if currentT == afterT and currentS == afterS: pass\n",
    "#     else:\n",
    "#             if currentT2 == beforeT and currentS == beforeS: pass\n",
    "#             else: return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variable to iterate through\n",
    "shape = fiona.open(XY_Points_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brett\\anaconda3\\envs\\CAFE\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: QgsVectorFileWriter constructor is deprecated\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# for loop to write line file between every 2 sequential points\n",
    "y = 0\n",
    "for feat in shape:\n",
    "    # Create if statement so you y is never > the length of your data set; this will end your script\n",
    "    if y + 1 < len(filter_dato):\n",
    "        # What file to write\n",
    "        file = linesFolder + \"\\line_\" + str(y) + \".shp\"\n",
    "        # Same as previous writer, except QgsWkbTypes. is LineString\n",
    "        writer = QgsVectorFileWriter(file, 'UTF-8', layerFields, QgsWkbTypes.LineString, \\\n",
    "                                 QgsCoordinateReferenceSystem('EPSG:26919'), 'ESRI Shapefile')\n",
    "        # y point in point_list will act as the start of the line\n",
    "        lineStart = point_list[y]\n",
    "        # y + 1 point in point_list will act as the end of the line\n",
    "        lineEnd = point_list[y+1]\n",
    "        # Creates line based on the start and end points previously specified\n",
    "        line = QgsGeometry.fromPolylineXY([lineStart, lineEnd])\n",
    "        # Create empty feature for line\n",
    "        linef = QgsFeature()\n",
    "        # Set geometry to previously created PolyLine\n",
    "        linef.setGeometry(line)\n",
    "        # Append attributes from dataframe\n",
    "        # Since the Line will consist of 2 points, both points' attributes must be stored in the line\n",
    "        linef.setAttributes([int(filter_dato['Point Number'].iloc[y]), \\\n",
    "                        filter_dato['Subclass'].iloc[y], filter_dato['Northing'].iloc[y].item(), \\\n",
    "                        filter_dato['Easting'].iloc[y].item(), filter_dato['Altitude'].iloc[y].item(), \\\n",
    "                        filter_dato['Pre Angle'].iloc[y].item(), \\\n",
    "                        filter_dato['Post Angle'].iloc[y].item(), filter_dato['Class'].iloc[y].item(), \\\n",
    "                        filter_dato['mu'].iloc[y].item(), filter_dato['Pre/Post'].iloc[y]])\n",
    "        # if statement so a line is only written if it belongs to the same transect\n",
    "        if filter_dato['Subclass'].iloc[y][:2] == filter_dato['Subclass'].iloc[y+1][:2]:\n",
    "            if filter_dato['Point Number'].iloc[y] + 1 == filter_dato['Point Number'].iloc[y+1]:\n",
    "                writer.addFeature(linef)\n",
    "                y += 1\n",
    "            else: y += 1\n",
    "        else:\n",
    "            y += 1\n",
    "    else: break\n",
    "del(writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = 0\n",
    "# for feat in shape.iterrows():\n",
    "#     print(filter_dato['mu'].iloc[y])\n",
    "#     y += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brett\\anaconda3\\envs\\CAFE\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: QgsVectorFileWriter constructor is deprecated\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Create new shapefile for Points that do not create a line\n",
    "\n",
    "y = 0\n",
    "shape = gpd.read_file(XY_Points_outfile)\n",
    "\n",
    "# for loop to write point for every mapping unit\n",
    "for feat in shape.iterrows():\n",
    "    # Create if statement so you y is never > the length of your data set; this will end your script\n",
    "    if filter_dato['mu'].iloc[y] == 1:\n",
    "            \n",
    "        # What file to write\n",
    "        file = mu_Folder + \"\\mu_\" + str(y) + \".shp\"\n",
    "        # Same as previous writer, except QgsWkbTypes. is Polygon\n",
    "        writer = QgsVectorFileWriter(file, 'UTF-8', layerFields, QgsWkbTypes.MultiPoint, \\\n",
    "                                QgsCoordinateReferenceSystem('EPSG:26919'), 'ESRI Shapefile')\n",
    "        poly1 = QgsGeometry.fromPointXY(point_list[y])\n",
    "        feat1 = QgsFeature()\n",
    "        feat1.setGeometry(poly1)\n",
    "        feat1.setAttributes([int(filter_dato['Point Number'].iloc[y]), \\\n",
    "                    filter_dato['Subclass'].iloc[y], filter_dato['Northing'].iloc[y].item(), \\\n",
    "                    filter_dato['Easting'].iloc[y].item(), filter_dato['Altitude'].iloc[y].item(), \\\n",
    "                    filter_dato['Pre Angle'].iloc[y].item(), \\\n",
    "                    filter_dato['Post Angle'].iloc[y].item(), filter_dato['Class'].iloc[y].item(), \\\n",
    "                    filter_dato['mu'].iloc[y].item(), filter_dato['Pre/Post'].iloc[y]])\n",
    "        y += 1\n",
    "        writer.addFeature(feat1)\n",
    "    else: \n",
    "        y += 1\n",
    "del(writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate all PolyLine shapefiles into a single shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which folder to look in\n",
    "file = os.listdir(linesFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for all files ending in \".shp\"\n",
    "path = [os.path.join(linesFolder, i) for i in file if \".shp\" in i]\n",
    "\n",
    "# Concatenate to file specified in last line of code\n",
    "gdf = gpd.GeoDataFrame(pd.concat([gpd.read_file(i) for i in path],\n",
    "                        ignore_index=True), crs=gpd.read_file(path[0]).crs)\n",
    "# Write to same folder + name of new folder to be created which will include the shapefile of compiled XY Points\n",
    "# Variable below is the suffix to add to linesFolder to specify folder to store compiled line files\n",
    "linesCompSuff = \"\\\\Lines_Comp\"\n",
    "gdf.to_file(linesFolder + linesCompSuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign compiled lines file path to variable linesCompiled\n",
    "linesCompiled = (linesFolder + linesCompSuff + linesCompSuff + \".shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Look for all files ending in \".shp\"\n",
    "# path = [os.path.join(mu_Folder, i) for i in file if \".shp\" in i]\n",
    "\n",
    "# # Concatenate to file specified in last line of code\n",
    "# gdf = gpd.GeoDataFrame(pd.concat([gpd.read_file(i) for i in path],\n",
    "#                         ignore_index=True), crs=gpd.read_file(path[0]).crs)\n",
    "# # Write to same folder + name of new folder to be created which will include the shapefile of compiled XY Points\n",
    "# # Variable below is the suffix to add to linesFolder to specify folder to store compiled line files\n",
    "# muCompSuff = \"\\\\mu_Comp\"\n",
    "# gdf.to_file(mu_Folder + muCompSuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assign compiled lines file path to variable linesCompiled\n",
    "# muCompiled = (mu_Folder + muCompSuff + muCompSuff + \".shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buffer the Lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buffer lines\n",
    "# Assign empty folder to variable to write new file to\n",
    "linesBufferFolder = Buffer_Folder\n",
    "# Read in line shapefile of transects\n",
    "lines= gpd.read_file(linesCompiled)\n",
    "# Assign buffer and keep attributes\n",
    "lines['geometry'] = lines.buffer(1, cap_style=3)\n",
    "# Write new shapefile\n",
    "lines.to_file(linesBufferFolder + \"\\\\Lines_Buffer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buffer mapping units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which folder to look in to buffer mu\n",
    "file = os.listdir(mu_Folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign empty folder to variable to write new file to\n",
    "muBufferFolder = mu_Buffer_Folder\n",
    "# # Read in line shapefile of transects\n",
    "# mus= gpd.read_file(muCompiled)\n",
    "# # Assign buffer and keep attributes\n",
    "# mus['geometry'] = mus.buffer(1, cap_style=3).rotate(filter_dato['Post Angle'][1], origin='center')\n",
    "# # Write new shapefile\n",
    "# mus.to_file(muBufferFolder + \"\\\\mu_Buffer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = [os.path.join(mu_Folder, i) for i in file if \".shp\" in i]\n",
    "y = 0\n",
    "for i in path:\n",
    "    mus = gpd.read_file(path[y])\n",
    "    if mus['Pre/Post'][0] == \"post\": \n",
    "        mus['geometry'] = mus.buffer(1, cap_style=3).rotate(mus[\"Post Angle\"][0], origin='center')\n",
    "        mus.to_file(muBufferFolder + \"\\\\mu_\" + str(mus[\"PointNum\"][0]) + \"_Buffer.shp\")\n",
    "    else: \n",
    "        mus['geometry'] = mus.buffer(1, cap_style=3).rotate(mus[\"Pre Angle\"][0], origin='center')\n",
    "        mus.to_file(muBufferFolder + \"\\\\mu_\" + str(mus[\"PointNum\"][0]) + \"_Buffer.shp\")\n",
    "    y += 1\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which folder to look in to compile mu\n",
    "file = os.listdir(muBufferFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for all files ending in \".shp\"\n",
    "path = [os.path.join(muBufferFolder, i) for i in file if \".shp\" in i]\n",
    "\n",
    "# Concatenate to file specified in last line of code\n",
    "gdf = gpd.GeoDataFrame(pd.concat([gpd.read_file(i) for i in path],\n",
    "                        ignore_index=True), crs=gpd.read_file(path[0]).crs)\n",
    "# Write to same folder + name of new folder to be created which will include the shapefile of compiled XY Points\n",
    "# Variable below is the suffix to add to linesFolder to specify folder to store compiled line files\n",
    "muCompSuff = \"\\\\mu_Comp\"\n",
    "gdf.to_file(muBufferFolder + muCompSuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Point Number</th>\n",
       "      <th>Subclass</th>\n",
       "      <th>Northing</th>\n",
       "      <th>Easting</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Pre Angle</th>\n",
       "      <th>Post Angle</th>\n",
       "      <th>Class</th>\n",
       "      <th>mu</th>\n",
       "      <th>Pre/Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>21jn</td>\n",
       "      <td>4737063.369</td>\n",
       "      <td>347660.272</td>\n",
       "      <td>1.125</td>\n",
       "      <td>-32.985121</td>\n",
       "      <td>-129.786569</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>post:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>21jn</td>\n",
       "      <td>4737058.029</td>\n",
       "      <td>347655.825</td>\n",
       "      <td>1.103</td>\n",
       "      <td>-129.786569</td>\n",
       "      <td>50.651079</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>post:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>21jn</td>\n",
       "      <td>4737068.191</td>\n",
       "      <td>347664.157</td>\n",
       "      <td>1.041</td>\n",
       "      <td>50.651079</td>\n",
       "      <td>-58.994755</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>post:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>21jn</td>\n",
       "      <td>4737067.785</td>\n",
       "      <td>347664.401</td>\n",
       "      <td>1.048</td>\n",
       "      <td>-58.994755</td>\n",
       "      <td>-127.605635</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>post:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>21jn</td>\n",
       "      <td>4737062.331</td>\n",
       "      <td>347660.200</td>\n",
       "      <td>1.037</td>\n",
       "      <td>-127.605635</td>\n",
       "      <td>-127.192770</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>post:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>21jn</td>\n",
       "      <td>4737057.044</td>\n",
       "      <td>347656.188</td>\n",
       "      <td>1.046</td>\n",
       "      <td>-127.192770</td>\n",
       "      <td>43.204500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>pre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Point Number Subclass     Northing     Easting  Altitude   Pre Angle  \\\n",
       "92            93     21jn  4737063.369  347660.272     1.125  -32.985121   \n",
       "93            94     21jn  4737058.029  347655.825     1.103 -129.786569   \n",
       "94            95     21jn  4737068.191  347664.157     1.041   50.651079   \n",
       "95            96     21jn  4737067.785  347664.401     1.048  -58.994755   \n",
       "96            97     21jn  4737062.331  347660.200     1.037 -127.605635   \n",
       "97            98     21jn  4737057.044  347656.188     1.046 -127.192770   \n",
       "\n",
       "    Post Angle  Class  mu Pre/Post  \n",
       "92 -129.786569      2   0    post:  \n",
       "93   50.651079      2   0    post:  \n",
       "94  -58.994755      2   0    post:  \n",
       "95 -127.605635      2   0    post:  \n",
       "96 -127.192770      2   0    post:  \n",
       "97   43.204500      2   0      pre  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ditch = waterFilter[28:34]\n",
    "ditch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    POLYGON ((347655.825 4737058.029, 347660.272 4...\n",
      "Name: geometry, dtype: geometry\n"
     ]
    }
   ],
   "source": [
    "northList = ditch['Northing'].tolist()\n",
    "eastList = ditch['Easting'].tolist()\n",
    "\n",
    "# Swap function must be called because 1st point on ditch polygons is the center point\n",
    "# Swap allows the polygon to \"begin\" at a corner; where the last point will connect to\n",
    "# Swap function \n",
    "def swapPositions(list, pos1, pos2): \n",
    "      \n",
    "    list[pos1], list[pos2] = list[pos2], list[pos1] \n",
    "    return list\n",
    "pos1 = 0\n",
    "pos2 = 1\n",
    "\n",
    "polygon_geom = Polygon(zip(swapPositions(eastList, pos1, pos2), swapPositions(northList, pos1, pos2)))\n",
    "crs = {'init': 'epsg:26919'}\n",
    "polygon = gpd.GeoDataFrame(index=[0], crs=crs, geometry=[polygon_geom]) \n",
    "print(polygon.geometry)\n",
    "\n",
    "polygon.to_file(filename = Polygon_Folder + '\\ditch1_22jn.shp', driver = 'ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[94, 93, 95, 96, 97, 98]\n"
     ]
    }
   ],
   "source": [
    "pList = ditch['Point Number'].tolist()\n",
    "pos1 = 0\n",
    "pos2 = 1\n",
    "# Swap function \n",
    "def swapPositions(list, pos1, pos2): \n",
    "      \n",
    "    list[pos1], list[pos2] = list[pos2], list[pos1] \n",
    "    return list\n",
    "print(swapPositions(pList, pos1, pos2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After erasing overlaps in QGIS, concatenate transect buffers and mu buffers together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify files to variables\n",
    "\n",
    "linebuffFinal = r\"G:\\.shortcut-targets-by-id\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\SaltMUAS_share\\EPA Salt Marsh UAS Study\\Red River\\Jupyter_Test_RR15aug2019\\Lines_Buffered\\Lines_Buffer\\Lines_Buffer.shp\"\n",
    "muFinal = r\"G:\\.shortcut-targets-by-id\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\SaltMUAS_share\\EPA Salt Marsh UAS Study\\Red River\\Jupyter_Test_RR15aug2019\\mu_Buffered\\mu_Comp\\mu_Comp.shp\"\n",
    "\n",
    "# Specify output\n",
    "\n",
    "finalOutput = r\"G:\\.shortcut-targets-by-id\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\SaltMUAS_share\\UAS Data Collection\\Red River\\2019\\Transects_Working\\RR_15_Aug_2019transects_Final.shp\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for all files ending in \".shp\"\n",
    "path = [linebuffFinal, muFinal]\n",
    "\n",
    "# Concatenate to file specified in last line of code\n",
    "gdf = gpd.GeoDataFrame(pd.concat([gpd.read_file(i) for i in path],\n",
    "                        ignore_index=True), crs=gpd.read_file(path[0]).crs)\n",
    "# Write to same folder + name of new folder to be created which will include the shapefile of compiled XY Points\n",
    "# Variable below is the suffix to add to linesFolder to specify folder to store compiled line files\n",
    "gdf.to_file(finalOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_lineBuffer = r\"G:\\.shortcut-targets-by-id\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\SaltMUAS_share\\EPA Salt Marsh UAS Study\\Red River\\Jupyter_Test_RR15aug2019\\Lines_Buffered\\Lines_Buffer\\Lines_Buffer.shp\"\n",
    "# final_muBuffer = r\"G:\\.shortcut-targets-by-id\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\SaltMUAS_share\\EPA Salt Marsh UAS Study\\Red River\\Jupyter_Test_RR15aug2019\\mu_Buffered\\mu_Comp\\mu_Comp.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fiona.collection.Collection"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Load shapefiles with fiona\n",
    "\n",
    "# fc_A = fiona.open(final_lineBuffer)\n",
    "# fc_B = fiona.open(final_muBuffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List to collect pairs of intersecting features\n",
    "# fc_intersect = []\n",
    "\n",
    "# with fiona.open(final_lineBuffer) as fc_A:\n",
    "#     for featA in fc_A:\n",
    "#         with fiona.open(final_muBuffer) as fc_B:\n",
    "#             for featB in fc_B:\n",
    "#                 if shape(featA['geometry']).intersects(shape(featB['geometry'])):\n",
    "#                     fc_intersect.append([featA, featB])\n",
    "# # This creates a list of dictionaries with points of overlap\n",
    "## https://gis.stackexchange.com/questions/311194/how-to-find-overlapping-polygons-of-two-shapefiles-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for use in the QGIS Python Console to remove buffers from overlapping Transects\n",
    "\n",
    "layer = iface.activeLayer()\n",
    "for f1 in layer.getFeatures():\n",
    "    for f2 in layer.getFeatures():\n",
    "        if f1.id() < f2.id():\n",
    "            geom1 = f1.geometry()\n",
    "            geom2 = f2.geometry()\n",
    "            new_geom = geom2.difference(geom1)\n",
    "            layer.dataProvider().changeGeometryValues({f2.id(): new_geom})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

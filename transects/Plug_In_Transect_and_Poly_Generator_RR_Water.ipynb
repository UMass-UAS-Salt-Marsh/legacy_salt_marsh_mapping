{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtCore import *\n",
    "import pandas as pd\n",
    "from qgis.core import *\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "from shapely.geometry import shape\n",
    "from shapely.geometry import Polygon\n",
    "from rtree import index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Increase width of notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to be used in script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to check for transect numbers of before and after points\n",
    "\n",
    "def transectCheck(rownumber, dataframe):\n",
    "    current = dataframe['Transect'].iloc[rownumber]\n",
    "    after = dataframe['Transect'].iloc[rownumber + 1]\n",
    "    if \"/\" in current:\n",
    "        slash1 = current.find(\"/\")\n",
    "        slash2 = slash1 + 1\n",
    "        current = current[slash2:]\n",
    "    elif \",\" in current:\n",
    "        slash1 = current.find(\",\")\n",
    "        slash2 = slash1 + 1\n",
    "        current = current[slash2:]\n",
    "    else: pass\n",
    "    \n",
    "    if \"/\" in after:\n",
    "        slash = after.find(\"/\")\n",
    "        after = after[:slash]\n",
    "        \n",
    "    elif \",\" in after:\n",
    "        slash = after.find(\",\")\n",
    "        after = after[:slash]\n",
    "        \n",
    "    else: pass\n",
    "    \n",
    "    if current == after:\n",
    "        return 1\n",
    "    else: return 0\n",
    "    \n",
    "    \n",
    "# Create function to determine if a point is a mapping unit\n",
    "\n",
    "def muCheck(rownumber, dataframe):\n",
    "    # Check transects\n",
    "    currentT = dataframe['Transect'].iloc[rownumber].replace(\" \", \"\")\n",
    "    currentT2 = dataframe['Transect'].iloc[rownumber].replace(\" \", \"\")    \n",
    "    beforeT = dataframe['Transect'].iloc[rownumber - 1].replace(\" \", \"\")\n",
    "    afterT = dataframe['Transect'].iloc[rownumber + 1].replace(\" \", \"\")\n",
    "    if \"/\" in currentT:\n",
    "        slash1 = currentT.find(\"/\")\n",
    "        slash2 = slash1 + 1\n",
    "        currentT = currentT[slash2:]\n",
    "        currentT2 = currentT2[:slash1]\n",
    "    else: pass\n",
    "    if \"/\" in afterT:\n",
    "        slash = afterT.find(\"/\")\n",
    "        afterT = afterT[:slash]\n",
    "    else: pass\n",
    "    if \"/\" in beforeT:\n",
    "        slash3 = beforeT.find(\"/\")\n",
    "        slash4 = slash3 + 1\n",
    "        beforeT = beforeT[slash4:]\n",
    "    else: pass\n",
    "    \n",
    "    # Check again in case of \",\"\n",
    "    currentT = dataframe['Transect'].iloc[rownumber].replace(\" \", \"\")\n",
    "    currentT2 = dataframe['Transect'].iloc[rownumber].replace(\" \", \"\")    \n",
    "    beforeT = dataframe['Transect'].iloc[rownumber - 1].replace(\" \", \"\")\n",
    "    afterT = dataframe['Transect'].iloc[rownumber + 1].replace(\" \", \"\")\n",
    "    if \",\" in currentT:\n",
    "        slash1 = currentT.find(\",\")\n",
    "        slash2 = slash1 + 1\n",
    "        currentT = currentT[slash2:]\n",
    "        currentT2 = currentT2[:slash1]\n",
    "    else: pass\n",
    "    if \",\" in afterT:\n",
    "        slash = afterT.find(\",\")\n",
    "        afterT = afterT[:slash]\n",
    "    else: pass\n",
    "    if \",\" in beforeT:\n",
    "        slash3 = beforeT.find(\",\")\n",
    "        slash4 = slash3 + 1\n",
    "        beforeT = beforeT[slash4:]\n",
    "    else: pass\n",
    "    \n",
    "    # Check subclasses\n",
    "    currentS = dataframe['Subclass'].iloc[rownumber][:2]\n",
    "    beforeS = dataframe['Subclass'].iloc[rownumber - 1][:2]\n",
    "    afterS = dataframe['Subclass'].iloc[rownumber + 1][:2]\n",
    "    \n",
    "    # Check 'Notes' field for mu\n",
    "    \n",
    "    \n",
    "    if currentT == afterT and currentS == afterS: pass\n",
    "    else:\n",
    "            if currentT2 == beforeT and currentS == beforeS: pass\n",
    "            else: return 2\n",
    "            \n",
    "def muClassCheck(rownumber, dataframe):\n",
    "    # Check transects\n",
    "    currentT = dataframe['Transect'].iloc[rownumber]\n",
    "    currentT2 = dataframe['Transect'].iloc[rownumber]    \n",
    "    beforeT = dataframe['Transect'].iloc[rownumber - 1]\n",
    "    afterT = dataframe['Transect'].iloc[rownumber + 1]\n",
    "    if \"/\" in currentT:\n",
    "        slash1 = currentT.find(\"/\")\n",
    "        slash2 = slash1 + 1\n",
    "        currentT = currentT[slash2:]\n",
    "        currentT2 = currentT2[:slash1]\n",
    "    else: pass\n",
    "    if \"/\" in afterT:\n",
    "        slash = afterT.find(\"/\")\n",
    "        afterT = afterT[:slash]\n",
    "    else: pass\n",
    "    if \"/\" in beforeT:\n",
    "        slash3 = beforeT.find(\"/\")\n",
    "        slash4 = slash3 + 1\n",
    "        beforeT = beforeT[slash4:]\n",
    "    else: pass\n",
    "    \n",
    "    # Check subclasses\n",
    "    currentS = dataframe['Class'].iloc[rownumber]\n",
    "    beforeS = dataframe['Class'].iloc[rownumber - 1]\n",
    "    afterS = dataframe['Class'].iloc[rownumber + 1]\n",
    "\n",
    "    if currentT == afterT and currentS == afterS: pass\n",
    "    else:\n",
    "            if currentT2 == beforeT and currentS == beforeS: pass\n",
    "            else: return 2\n",
    "            \n",
    "def muCheckLast(rownumber, dataframe):\n",
    "    # Check final subclass with [-1] subclass only\n",
    "    currentS = dataframe['Subclass'].iloc[rownumber][:2]\n",
    "    beforeS = dataframe['Subclass'].iloc[rownumber - 1][:2]\n",
    "    \n",
    "    if currentS == beforeS: pass\n",
    "    else: return 2\n",
    "    \n",
    "def muClassCheckLast(rownumber, dataframe):\n",
    "    # Check final subclass with [-1] subclass only\n",
    "    currentS = dataframe['Class'].iloc[rownumber][:2]\n",
    "    beforeS = dataframe['Class'].iloc[rownumber - 1][:2]\n",
    "    \n",
    "    if currentS == beforeS: pass\n",
    "    else: return 2\n",
    "\n",
    "# Define function to test whether angle of mu corresponds to pre or post angle\n",
    "\n",
    "def prepostCheck(rownumber, dataframe):\n",
    "    currentT = dataframe['Transect'].iloc[rownumber]\n",
    "    afterT = dataframe['Transect'].iloc[rownumber + 1]\n",
    "    \n",
    "    if \"/\" in currentT:\n",
    "        slash1 = currentT.find(\"/\")\n",
    "        slash2 = slash1 + 1\n",
    "        currentT = currentT[slash2:]\n",
    "    else: pass\n",
    "    \n",
    "    if \"/\" in afterT:\n",
    "        slash = afterT.find(\"/\")\n",
    "        afterT = afterT[:slash]\n",
    "    else: pass\n",
    "    \n",
    "    if currentT == afterT: return \"post\"\n",
    "    else: return \"pre\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Up the Data - Specify correct folders to be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter file path to site folder in EPA Salt Marsh UAS Study with quotations -- \"G:\\.shortcut-targets-by-id\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\SaltMUAS_share\\EPA Salt Marsh UAS Study\\Red River\"\n",
      "Enter in the date and site in the format: RR_14_Aug_2019 -- RR_13_Aug_2019\n",
      "G:\\.shortcut-targets-by-id\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\SaltMUAS_share\\EPA Salt Marsh UAS Study\\Red River\\Jupyter_Working_Folder\\RR_13_Aug_2019 created.\n",
      "G:\\.shortcut-targets-by-id\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\SaltMUAS_share\\EPA Salt Marsh UAS Study\\Red River\\Jupyter_Working_Folder\\RR_13_Aug_2019\\XY_Points created.\n",
      "G:\\.shortcut-targets-by-id\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\SaltMUAS_share\\EPA Salt Marsh UAS Study\\Red River\\Jupyter_Working_Folder\\RR_13_Aug_2019\\Lines created.\n",
      "G:\\.shortcut-targets-by-id\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\SaltMUAS_share\\EPA Salt Marsh UAS Study\\Red River\\Jupyter_Working_Folder\\RR_13_Aug_2019\\Lines_Buffered created.\n",
      "G:\\.shortcut-targets-by-id\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\SaltMUAS_share\\EPA Salt Marsh UAS Study\\Red River\\Jupyter_Working_Folder\\RR_13_Aug_2019\\mu created.\n",
      "G:\\.shortcut-targets-by-id\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\SaltMUAS_share\\EPA Salt Marsh UAS Study\\Red River\\Jupyter_Working_Folder\\RR_13_Aug_2019\\mu_Buffered created.\n",
      "G:\\.shortcut-targets-by-id\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\SaltMUAS_share\\EPA Salt Marsh UAS Study\\Red River\\Jupyter_Working_Folder\\RR_13_Aug_2019\\Class_Lines created.\n",
      "G:\\.shortcut-targets-by-id\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\SaltMUAS_share\\EPA Salt Marsh UAS Study\\Red River\\Jupyter_Working_Folder\\RR_13_Aug_2019\\Class_Lines_Buffered created.\n",
      "G:\\.shortcut-targets-by-id\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\SaltMUAS_share\\EPA Salt Marsh UAS Study\\Red River\\Jupyter_Working_Folder\\RR_13_Aug_2019\\working created.\n",
      "G:\\.shortcut-targets-by-id\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\SaltMUAS_share\\EPA Salt Marsh UAS Study\\Red River\\Jupyter_Working_Folder\\RR_13_Aug_2019\\Polygons created.\n",
      "Folder creation complete.\n"
     ]
    }
   ],
   "source": [
    "# Create directories within selected folder\n",
    "\n",
    "# If tapping into Google Drive, folder may need to be availble offline\n",
    "\n",
    "root = input(\"Enter file path to site folder in EPA Salt Marsh UAS Study with quotations -- \")\n",
    "root = root[1:-1]\n",
    "base = root + \"\\Jupyter_Working_Folder\"\n",
    "workIn = input(\"Enter in the date and site in the format: RR_14_Aug_2019 -- \")\n",
    "currentWork = base + \"\\\\\" + workIn\n",
    "XY_Points_Folder = currentWork + \"\\XY_Points\"\n",
    "Lines_Folder = currentWork + \"\\Lines\"\n",
    "Buffer_Folder = currentWork + \"\\Lines_Buffered\"\n",
    "Class_Lines_Folder = currentWork + \"\\Class_Lines\"\n",
    "Class_Buffer_Folder = currentWork + \"\\Class_Lines_Buffered\"\n",
    "mu_Folder = currentWork + \"\\mu\"\n",
    "mu_Buffer_Folder = currentWork + \"\\mu_Buffered\"\n",
    "working = currentWork + \"\\working\"\n",
    "Polygon_Folder = currentWork + \"\\Polygons\"\n",
    "folderList = [currentWork, XY_Points_Folder, Lines_Folder, Buffer_Folder, mu_Folder, \n",
    "              mu_Buffer_Folder, Class_Lines_Folder, Class_Buffer_Folder, working, Polygon_Folder]\n",
    "for i in folderList:\n",
    "    if not os.path.exists(i):\n",
    "        os.makedirs(i)\n",
    "        print(str(i) + \" created.\")\n",
    "print(\"Folder creation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check data to edit cell below to determine number of rows to exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter file path to ground truthing data .csv here -- \"G:\\.shortcut-targets-by-id\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\SaltMUAS_share\\EPA Salt Marsh UAS Study\\Red River\\Ground Truthing\\redriver13oct2019_revised.csv\"\n"
     ]
    }
   ],
   "source": [
    "# Read in .cvs with Transects\n",
    "# Keep quotations around file path in the input\n",
    "read_data = input(\"Enter file path to ground truthing data .csv here -- \")\n",
    "read_data = read_data[1:-1]\n",
    "\n",
    "# skiprows argument may need to be tweaked depending on format of the .csv's headers\n",
    "df = pd.read_csv(read_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transect</th>\n",
       "      <th>Point Number</th>\n",
       "      <th>Subclass</th>\n",
       "      <th>Northing</th>\n",
       "      <th>Easting</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Class</th>\n",
       "      <th>Raw Subclass</th>\n",
       "      <th>Pre Angle</th>\n",
       "      <th>Post Angle</th>\n",
       "      <th>mu</th>\n",
       "      <th>Class mu</th>\n",
       "      <th>Pre/Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>RTCM0057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4615954.563</td>\n",
       "      <td>419521.345</td>\n",
       "      <td>15.109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22jr</td>\n",
       "      <td>4613505.107</td>\n",
       "      <td>413591.985</td>\n",
       "      <td>0.437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>22jr</td>\n",
       "      <td>4613509.455</td>\n",
       "      <td>413592.060</td>\n",
       "      <td>0.484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>22jr</td>\n",
       "      <td>4613515.323</td>\n",
       "      <td>413589.871</td>\n",
       "      <td>0.742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>22jr</td>\n",
       "      <td>4613518.660</td>\n",
       "      <td>413591.076</td>\n",
       "      <td>0.529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Transect Point Number Subclass     Northing     Easting  Altitude Notes  \\\n",
       "0       NaN     RTCM0057      NaN  4615954.563  419521.345    15.109   NaN   \n",
       "1       1.0            1     22jr  4613505.107  413591.985     0.437   NaN   \n",
       "2       2.0            2     22jr  4613509.455  413592.060     0.484   NaN   \n",
       "3       3.0            3     22jr  4613515.323  413589.871     0.742   NaN   \n",
       "4       4.0            4     22jr  4613518.660  413591.076     0.529   NaN   \n",
       "\n",
       "   Class  Raw Subclass  Pre Angle  Post Angle   mu  Class mu  Pre/Post  \n",
       "0    NaN           NaN        NaN         NaN  NaN       NaN       NaN  \n",
       "1    NaN           NaN        NaN         NaN  1.0       NaN       NaN  \n",
       "2    NaN           NaN        NaN         NaN  1.0       NaN       NaN  \n",
       "3    NaN           NaN        NaN         NaN  1.0       NaN       NaN  \n",
       "4    NaN           NaN        NaN         NaN  1.0       NaN       NaN  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observe number of rows to discard including RTC data\n",
    "print(\"Preview of data:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If dataframe start at the correct positional row, enter 1, if not, enter 2 -- 2\n",
      "Enter in number of rows to discard -- 1\n",
      "One row discarded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transect</th>\n",
       "      <th>Point Number</th>\n",
       "      <th>Subclass</th>\n",
       "      <th>Northing</th>\n",
       "      <th>Easting</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Class</th>\n",
       "      <th>Raw Subclass</th>\n",
       "      <th>Pre Angle</th>\n",
       "      <th>Post Angle</th>\n",
       "      <th>mu</th>\n",
       "      <th>Class mu</th>\n",
       "      <th>Pre/Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22jr</td>\n",
       "      <td>4613505.107</td>\n",
       "      <td>413591.985</td>\n",
       "      <td>0.437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>22jr</td>\n",
       "      <td>4613509.455</td>\n",
       "      <td>413592.060</td>\n",
       "      <td>0.484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>22jr</td>\n",
       "      <td>4613515.323</td>\n",
       "      <td>413589.871</td>\n",
       "      <td>0.742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>22jr</td>\n",
       "      <td>4613518.660</td>\n",
       "      <td>413591.076</td>\n",
       "      <td>0.529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>22jr</td>\n",
       "      <td>4613520.181</td>\n",
       "      <td>413590.477</td>\n",
       "      <td>0.501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Transect Point Number Subclass     Northing     Easting  Altitude Notes  \\\n",
       "1       1.0            1     22jr  4613505.107  413591.985     0.437   NaN   \n",
       "2       2.0            2     22jr  4613509.455  413592.060     0.484   NaN   \n",
       "3       3.0            3     22jr  4613515.323  413589.871     0.742   NaN   \n",
       "4       4.0            4     22jr  4613518.660  413591.076     0.529   NaN   \n",
       "5       5.0            5     22jr  4613520.181  413590.477     0.501   NaN   \n",
       "\n",
       "   Class  Raw Subclass  Pre Angle  Post Angle   mu  Class mu  Pre/Post  \n",
       "1    NaN           NaN        NaN         NaN  1.0       NaN       NaN  \n",
       "2    NaN           NaN        NaN         NaN  1.0       NaN       NaN  \n",
       "3    NaN           NaN        NaN         NaN  1.0       NaN       NaN  \n",
       "4    NaN           NaN        NaN         NaN  1.0       NaN       NaN  \n",
       "5    NaN           NaN        NaN         NaN  1.0       NaN       NaN  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove top rows of data if necessary\n",
    "dat = input(\"If dataframe start at the correct positional row, enter 1, if not, enter 2 -- \")\n",
    "if dat == \"2\":\n",
    "    num = int(input(\"Enter in number of rows to discard -- \"))\n",
    "    if num == 1:\n",
    "        datos = df.iloc[1:]\n",
    "        dato = pd.DataFrame(datos)\n",
    "        print(\"One row discarded\")\n",
    "    elif num == 2:\n",
    "        datos = df.iloc[2:]\n",
    "        dato = pd.DataFrame(datos)  \n",
    "        print(\"Two rows discarded\")\n",
    "    elif num == 3:\n",
    "        datos = df.iloc[3:]\n",
    "        dato = pd.DataFrame(datos) \n",
    "        print(\"Three rows discarded\")\n",
    "    else:\n",
    "        datos = df.iloc[4:]\n",
    "        dato = pd.DataFrame(datos)  \n",
    "        print(\"Rows discarded\")\n",
    "else: dato = pd.DataFrame(df)\n",
    "dato.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column headers\n",
    "# dato.columns = ['Transect', 'Point Number', 'Subclass', 'Northing', 'Easting', 'Altitude', 'Notes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for null values where Transect != NaN \n",
    "filter_dato = dato[dato['Transect'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transect</th>\n",
       "      <th>Point Number</th>\n",
       "      <th>Subclass</th>\n",
       "      <th>Northing</th>\n",
       "      <th>Easting</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Class</th>\n",
       "      <th>Raw Subclass</th>\n",
       "      <th>Pre Angle</th>\n",
       "      <th>Post Angle</th>\n",
       "      <th>mu</th>\n",
       "      <th>Class mu</th>\n",
       "      <th>Pre/Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22jr</td>\n",
       "      <td>4613505.107</td>\n",
       "      <td>413591.985</td>\n",
       "      <td>0.437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>22jr</td>\n",
       "      <td>4613509.455</td>\n",
       "      <td>413592.060</td>\n",
       "      <td>0.484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>22jr</td>\n",
       "      <td>4613515.323</td>\n",
       "      <td>413589.871</td>\n",
       "      <td>0.742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>22jr</td>\n",
       "      <td>4613518.660</td>\n",
       "      <td>413591.076</td>\n",
       "      <td>0.529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>22jr</td>\n",
       "      <td>4613520.181</td>\n",
       "      <td>413590.477</td>\n",
       "      <td>0.501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Transect Point Number Subclass     Northing     Easting  Altitude Notes  \\\n",
       "1       1.0            1     22jr  4613505.107  413591.985     0.437   NaN   \n",
       "2       2.0            2     22jr  4613509.455  413592.060     0.484   NaN   \n",
       "3       3.0            3     22jr  4613515.323  413589.871     0.742   NaN   \n",
       "4       4.0            4     22jr  4613518.660  413591.076     0.529   NaN   \n",
       "5       5.0            5     22jr  4613520.181  413590.477     0.501   NaN   \n",
       "\n",
       "   Class  Raw Subclass  Pre Angle  Post Angle   mu  Class mu  Pre/Post  \n",
       "1    NaN           NaN        NaN         NaN  1.0       NaN       NaN  \n",
       "2    NaN           NaN        NaN         NaN  1.0       NaN       NaN  \n",
       "3    NaN           NaN        NaN         NaN  1.0       NaN       NaN  \n",
       "4    NaN           NaN        NaN         NaN  1.0       NaN       NaN  \n",
       "5    NaN           NaN        NaN         NaN  1.0       NaN       NaN  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Create empty fields for transect angles, Class, and mapping unit\n",
    "\n",
    "# filter_dato['Class'] = \"\"\n",
    "# filter_dato[\"Raw Subclass\"] = \"\"\n",
    "# filter_dato['Pre Angle'] = \"\"\n",
    "# filter_dato['Post Angle'] = \"\"\n",
    "# filter_dato['mu'] = \"\"\n",
    "# filter_dato['Class mu'] = \"\"\n",
    "# filter_dato[\"Pre/Post\"] = \"\"\n",
    "\n",
    "\n",
    "# Preview the data\n",
    "filter_dato.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use this cell to alter the data if needed\n",
    "\n",
    "# input(\"Press Enter after confirming cell alters data as needed; stop running Notebook if not\")\n",
    "\n",
    "# filter_dato = filter_dato.drop([filter_dato.index[103] , filter_dato.index[104] , filter_dato.index[105]])\n",
    "\n",
    "# filter_dato['Transect'][10] = filter_dato['Transect'][10].replace(\" \", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brett\\anaconda3\\envs\\CAFE\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\brett\\anaconda3\\envs\\CAFE\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\brett\\anaconda3\\envs\\CAFE\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\brett\\anaconda3\\envs\\CAFE\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Convert any strings to floats or ints\n",
    "\n",
    "filter_dato['Point Number'] = list(map(int, filter_dato['Point Number']))\n",
    "filter_dato['Northing'] = list(map(float, filter_dato['Northing']))\n",
    "filter_dato['Easting'] = list(map(float, filter_dato['Easting']))\n",
    "filter_dato['Altitude'] = list(map(float, filter_dato['Altitude']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables of lists of coordinates of current, before, and after coordinates\n",
    "# This will be used to calculate angle from one point to the next\n",
    "\n",
    "y = 0\n",
    "precoordN = []\n",
    "for x in filter_dato.iterrows():\n",
    "    precoordN.append(filter_dato['Northing'].iloc[y-1])\n",
    "    y += 1\n",
    "y = 0\n",
    "precoordE = []\n",
    "for x in filter_dato.iterrows():\n",
    "    precoordE.append(filter_dato['Easting'].iloc[y-1])\n",
    "    y += 1\n",
    "y = 0\n",
    "currcoordN = []\n",
    "for x in filter_dato.iterrows():\n",
    "    currcoordN.append(filter_dato['Northing'].iloc[y])\n",
    "    y += 1\n",
    "y = 0\n",
    "currcoordE = []\n",
    "for x in filter_dato.iterrows():\n",
    "    currcoordE.append(filter_dato['Easting'].iloc[y])\n",
    "    y += 1\n",
    "y = 0\n",
    "postcoordN = []\n",
    "for x in filter_dato.iterrows():\n",
    "    if y+1 < len(filter_dato):\n",
    "        postcoordN.append(filter_dato['Northing'].iloc[y+1])\n",
    "        y += 1\n",
    "    else: break\n",
    "y = 0\n",
    "postcoordE = []\n",
    "for x in filter_dato.iterrows():\n",
    "    if y+1 < len(filter_dato):\n",
    "        postcoordE.append(filter_dato['Easting'].iloc[y+1])\n",
    "        y += 1\n",
    "    else: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert any strings to floats\n",
    "\n",
    "# precoordN = list(map(float, precoordN))\n",
    "# precoordE = list(map(float, precoordE))\n",
    "# currcoordN = list(map(float, currcoordN))\n",
    "# currcoordE = list(map(float, currcoordE))\n",
    "# postcoordN = list(map(float, postcoordN))\n",
    "# postcoordE = list(map(float, postcoordE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append calculated angles to lists\n",
    "y = 0\n",
    "preAngle = []\n",
    "for i in filter_dato.iterrows():\n",
    "    if y-1 < 0:\n",
    "        preAngle.append(0)\n",
    "        y += 1\n",
    "    else:\n",
    "        myradians = math.atan2(currcoordN[y]-precoordN[y], currcoordE[y]-precoordE[y])\n",
    "        mydegrees = math.degrees(myradians)\n",
    "        preAngle.append(mydegrees)\n",
    "        y += 1\n",
    "\n",
    "y = 0\n",
    "postAngle = []\n",
    "for i in filter_dato.iterrows():\n",
    "    if y+1 < len(filter_dato):\n",
    "        myradians = math.atan2(postcoordN[y]-currcoordN[y], postcoordE[y]-currcoordE[y])\n",
    "        mydegrees = math.degrees(myradians)\n",
    "        postAngle.append(mydegrees)\n",
    "        y += 1\n",
    "    else: \n",
    "        postAngle.append(0)\n",
    "        y += 1       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse out Class from Subclass and append to new list\n",
    "\n",
    "classe = []\n",
    "y = 0\n",
    "for i in filter_dato.iterrows():\n",
    "    if filter_dato['Subclass'].iloc[y][:1] == \"0\" or filter_dato['Subclass'].iloc[y][:1] == \"1\":\n",
    "        classe.append(1)\n",
    "        y += 1\n",
    "    elif filter_dato['Subclass'].iloc[y][:1] == \"2\":\n",
    "        classe.append(2)\n",
    "        y += 1\n",
    "    elif filter_dato['Subclass'].iloc[y][:1] == \"3\":\n",
    "        classe.append(3)\n",
    "        y += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse out Raw Subclass data with only letters - no attribute letters\n",
    "\n",
    "subraw = []\n",
    "y = 0\n",
    "for i in filter_dato[\"Subclass\"]:\n",
    "    subraw.append(str(i[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brett\\anaconda3\\envs\\CAFE\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\brett\\anaconda3\\envs\\CAFE\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\brett\\anaconda3\\envs\\CAFE\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\brett\\anaconda3\\envs\\CAFE\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Add lists to empty columns\n",
    "\n",
    "filter_dato['Pre Angle'] = preAngle\n",
    "filter_dato['Post Angle'] = postAngle\n",
    "filter_dato['Class'] = classe\n",
    "filter_dato[\"Raw Subclass\"] = subraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create new shapefile for Points that do not create a line\n",
    "# y = 0\n",
    "# muList = []\n",
    "\n",
    "# # for loop to write point for every mapping unit\n",
    "# for feat in filter_dato.iterrows():\n",
    "#     # Create if statement so you y is never > the length of your data set; this will end your script\n",
    "#     if y + 1 < len(filter_dato):\n",
    "#         if filter_dato['Raw Subclass'].iloc[y] == \"13\":\n",
    "#             muList.append(1)\n",
    "#         else:\n",
    "#             if muCheck(y, filter_dato) == 2:\n",
    "#                 muList.append(1)\n",
    "\n",
    "\n",
    "\n",
    "#                 y += 1\n",
    "#             else: \n",
    "#                 muList.append(0)\n",
    "#                 y += 1\n",
    "#     else:\n",
    "#         muList.append(1)\n",
    "        \n",
    "# # Repeart for Class mapping units\n",
    "\n",
    "# y = 0\n",
    "# ClassmuList = []\n",
    "# for feat in filter_dato.iterrows():\n",
    "#     if y + 1 < len(filter_dato):\n",
    "#         if muClassCheck(y, filter_dato) == 2:\n",
    "#             ClassmuList.append(1)\n",
    "            \n",
    "            \n",
    "\n",
    "#             y += 1\n",
    "#         else: \n",
    "#             ClassmuList.append(0)\n",
    "#             y += 1\n",
    "#     else:\n",
    "#         ClassmuList.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append muList to dataframe\n",
    "# filter_dato['mu'] = muList\n",
    "# filter_dato['Class mu'] = ClassmuList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input(\"Keep value as zero if the last point in the data is not a mapping unit. Press Enter. \")\n",
    "# filter_dato['mu'][-1:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brett\\anaconda3\\envs\\CAFE\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "filter_dato['Transect'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brett\\anaconda3\\envs\\CAFE\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "filter_dato['Transect'] = [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"12\",\"12\",\"13\",\"14\",\"15\",\"16\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create for loop to create list of pre or post to append to dataframe\n",
    "# This angle determines the angle the mapping unit should be rotated\n",
    "\n",
    "y = 0\n",
    "prepost = []\n",
    "\n",
    "for i in filter_dato.iterrows():\n",
    "    if y + 1 < len(filter_dato):\n",
    "        pp = prepostCheck(y, filter_dato)\n",
    "        prepost.append(pp)\n",
    "        y += 1\n",
    "    else: prepost.append(\"pre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brett\\anaconda3\\envs\\CAFE\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Append prepost list to dataframe\n",
    "\n",
    "filter_dato[\"Pre/Post\"] = prepost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create QGIS XY Point Data into a List based on coordinates\n",
    "point_list = [QgsPointXY(r['Easting'], r['Northing']) for i, r in filter_dato.iterrows() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Multipoint list\n",
    "points = QgsGeometry.fromMultiPointXY(point_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the XY Point Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create fields with correct data types\n",
    "\n",
    "layerFields = QgsFields()\n",
    "layerFields.append(QgsField('Transect', QVariant.String))\n",
    "layerFields.append(QgsField('PointNum', QVariant.Int))\n",
    "layerFields.append(QgsField('SubClass', QVariant.String))\n",
    "layerFields.append(QgsField('Northing', QVariant.Double))\n",
    "layerFields.append(QgsField('Easting', QVariant.Double))\n",
    "layerFields.append(QgsField('Altitude', QVariant.Double))\n",
    "layerFields.append(QgsField('Notes', QVariant.String))\n",
    "layerFields.append(QgsField('Class', QVariant.Int))\n",
    "layerFields.append(QgsField('Raw Subclass', QVariant.String))\n",
    "layerFields.append(QgsField('Pre Angle', QVariant.Double))\n",
    "layerFields.append(QgsField('Post Angle', QVariant.Double))\n",
    "layerFields.append(QgsField('mu', QVariant.Int))\n",
    "layerFields.append(QgsField('Class mu', QVariant.Int))\n",
    "layerFields.append(QgsField('Pre/Post', QVariant.String))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set attributes by assigning to list assigned to variable\n",
    "attributeList = [filter_dato['Transect'].iloc[y], \\\n",
    "                 int(filter_dato['Point Number'].iloc[y]), \\\n",
    "                 filter_dato['Subclass'].iloc[y], \\\n",
    "                 filter_dato['Northing'].iloc[y].item(), \\\n",
    "                 filter_dato['Easting'].iloc[y].item(), \\\n",
    "                 filter_dato['Altitude'].iloc[y].item(), \\\n",
    "                 filter_dato['Notes'].iloc[y], \\\n",
    "                 filter_dato['Class'].iloc[y].item(), \\\n",
    "                 filter_dato['Raw Subclass'].iloc[y], \\\n",
    "                 filter_dato['Pre Angle'].iloc[y].item(), \\\n",
    "                 filter_dato['Post Angle'].iloc[y].item(), \\\n",
    "                 filter_dato['mu'].iloc[y].item(),  \\\n",
    "                 filter_dato['Class mu'].iloc[y].item(), \\\n",
    "                 filter_dato['Pre/Post'].iloc[y]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write XY Point Data for each row in .csv\n",
    "# Specify output to variable\n",
    "XY_Output_Path = XY_Points_Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brett\\anaconda3\\envs\\CAFE\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: QgsVectorFileWriter constructor is deprecated\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Use for loop to create shapefile\n",
    "y = 0\n",
    "for x in filter_dato.itertuples():\n",
    "    # Specify file output and name of .shp\n",
    "    file = XY_Output_Path + \"\\XYPoint\" + str(y) + \".shp\"\n",
    "    # Set type (QgsWkbTypes.), CRS (EPSG:26919), and type of file (ESRI Shapefile)\n",
    "    writer = QgsVectorFileWriter(file, 'UTF-8', layerFields, QgsWkbTypes.MultiPoint, QgsCoordinateReferenceSystem('EPSG:26919'), 'ESRI Shapefile')\n",
    "    # Appends X and Y coordinates to variable 'point1' at the y position (starts at 0 and adds 1 for each iteration of the for loop)\n",
    "    point1 = QgsGeometry.fromPointXY(point_list[y])\n",
    "    # Create an empty feature\n",
    "    feat = QgsFeature()\n",
    "    # Set feature's geometry to that of point1\n",
    "    feat.setGeometry(point1)\n",
    "    # Set values from dataframe to attributes\n",
    "    # Values will be applied in the order you created the layerFields\n",
    "    feat.setAttributes([filter_dato['Transect'].iloc[y], \\\n",
    "                 int(filter_dato['Point Number'].iloc[y]), \\\n",
    "                 filter_dato['Subclass'].iloc[y], \\\n",
    "                 filter_dato['Northing'].iloc[y].item(), \\\n",
    "                 filter_dato['Easting'].iloc[y].item(), \\\n",
    "                 filter_dato['Altitude'].iloc[y].item(), \\\n",
    "                 filter_dato['Notes'].iloc[y], \\\n",
    "                 filter_dato['Class'].iloc[y].item(), \\\n",
    "                 filter_dato['Raw Subclass'].iloc[y], \\\n",
    "                 filter_dato['Pre Angle'].iloc[y].item(), \\\n",
    "                 filter_dato['Post Angle'].iloc[y].item(), \\\n",
    "                 filter_dato['mu'].iloc[y].item(),  \\\n",
    "                 filter_dato['Class mu'].iloc[y].item(), \\\n",
    "                 filter_dato['Pre/Post'].iloc[y]])\n",
    "    # Add 1 to y to continue through the dataframe during next for loop\n",
    "    y += 1\n",
    "    # write the feature\n",
    "    writer.addFeature(feat)\n",
    "\n",
    "del(writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate all XY Point shapefiles into a single shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which folder to look in\n",
    "file = os.listdir(XY_Output_Path)\n",
    "\n",
    "# Look for all files ending in \".shp\"\n",
    "path = [os.path.join(XY_Output_Path, i) for i in file if \".shp\" in i]\n",
    "\n",
    "# Concatenate to file specified in last line of code\n",
    "gdf = gpd.GeoDataFrame(pd.concat([gpd.read_file(i) for i in path],\n",
    "                        ignore_index=True), crs=gpd.read_file(path[0]).crs)\n",
    "# Write to same folder + name of new folder to be created which will include the shapefile of compiled XY Points\n",
    "XY_Points_Comp = \"\\XY_Points_Comp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write concatenated files to output path\n",
    "gdf.to_file(XY_Output_Path + XY_Points_Comp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort shapefile by Point Number attribute\n",
    "# Assign XY_Points__Outfile to where the sorted compiled XY Points will be saved\n",
    "XY_Points_outfile = XY_Output_Path + XY_Points_Comp + \"\\\\XY_Points_Comp_Sort.shp\"\n",
    "# Designate which compiled shapefile will be sorted\n",
    "filePath = XY_Output_Path + XY_Points_Comp + XY_Points_Comp + \".shp\"\n",
    "# Use geopandas to read in shapefile - Append read shapefile to variable 'shape'\n",
    "shape = gpd.read_file(filePath)\n",
    "# Sort based on Point Number\n",
    "shape_sort = shape.iloc[shape['PointNum'].sort_values().index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-write file back out as sorted compiled shapefile\n",
    "shape_sort.to_file(driver = 'ESRI Shapefile', filename = XY_Points_outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create PolyLine Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify empty folder to put the Line files in\n",
    "linesFolder = Lines_Folder\n",
    "classlinesFolder = Class_Lines_Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variable to iterate through\n",
    "shape = fiona.open(XY_Points_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brett\\anaconda3\\envs\\CAFE\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: QgsVectorFileWriter constructor is deprecated\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Create lines based on subclasses\n",
    "\n",
    "# for loop to write line file between every 2 sequential points with matching sublass\n",
    "y = 0\n",
    "for feat in shape:\n",
    "    # Create if statement so you y is never > the length of your data set; this will end your script\n",
    "    if y + 1 < len(filter_dato):\n",
    "        # What file to write\n",
    "        file = linesFolder + \"\\line_\" + str(y) + \".shp\"\n",
    "        # Same as previous writer, except QgsWkbTypes. is LineString\n",
    "        writer = QgsVectorFileWriter(file, 'UTF-8', layerFields, QgsWkbTypes.LineString, \\\n",
    "                                 QgsCoordinateReferenceSystem('EPSG:26919'), 'ESRI Shapefile')\n",
    "        # y point in point_list will act as the start of the line\n",
    "        lineStart = point_list[y]\n",
    "        # y + 1 point in point_list will act as the end of the line\n",
    "        lineEnd = point_list[y+1]\n",
    "        # Creates line based on the start and end points previously specified\n",
    "        line = QgsGeometry.fromPolylineXY([lineStart, lineEnd])\n",
    "        # Create empty feature for line\n",
    "        linef = QgsFeature()\n",
    "        # Set geometry to previously created PolyLine\n",
    "        linef.setGeometry(line)\n",
    "        # Append attributes from dataframe\n",
    "        # Since the Line will consist of 2 points, both points' attributes must be stored in the line\n",
    "        linef.setAttributes([filter_dato['Transect'].iloc[y], \\\n",
    "                 int(filter_dato['Point Number'].iloc[y]), \\\n",
    "                 filter_dato['Subclass'].iloc[y], \\\n",
    "                 filter_dato['Northing'].iloc[y].item(), \\\n",
    "                 filter_dato['Easting'].iloc[y].item(), \\\n",
    "                 filter_dato['Altitude'].iloc[y].item(), \\\n",
    "                 filter_dato['Notes'].iloc[y], \\\n",
    "                 filter_dato['Class'].iloc[y].item(), \\\n",
    "                 filter_dato['Raw Subclass'].iloc[y], \\\n",
    "                 filter_dato['Pre Angle'].iloc[y].item(), \\\n",
    "                 filter_dato['Post Angle'].iloc[y].item(), \\\n",
    "                 filter_dato['mu'].iloc[y].item(),  \\\n",
    "                 filter_dato['Class mu'].iloc[y].item(), \\\n",
    "                 filter_dato['Pre/Post'].iloc[y]])\n",
    "        # if statement so a line is only written if it belongs to the same transect\n",
    "        if filter_dato['Subclass'].iloc[y][:2] == filter_dato['Subclass'].iloc[y+1][:2] and transectCheck(y,filter_dato) == 1:\n",
    "            if filter_dato['mu'].iloc[y] == 1:\n",
    "                y +=1\n",
    "            else:\n",
    "                writer.addFeature(linef)\n",
    "                y += 1\n",
    "        else:\n",
    "            y += 1\n",
    "    else: break\n",
    "del(writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create lines based on Class\n",
    "\n",
    "# # for loop to write line file between every 2 sequential points with matching Class\n",
    "# y = 0\n",
    "# for feat in shape:\n",
    "#     # Create if statement so you y is never > the length of your data set; this will end your script\n",
    "#     if y + 1 < len(filter_dato):\n",
    "#         # What file to write\n",
    "#         file = classlinesFolder + \"\\line_\" + str(y) + \".shp\"\n",
    "#         # Same as previous writer, except QgsWkbTypes. is LineString\n",
    "#         writer = QgsVectorFileWriter(file, 'UTF-8', layerFields, QgsWkbTypes.LineString, \\\n",
    "#                                  QgsCoordinateReferenceSystem('EPSG:26919'), 'ESRI Shapefile')\n",
    "#         # y point in point_list will act as the start of the line\n",
    "#         lineStart = point_list[y]\n",
    "#         # y + 1 point in point_list will act as the end of the line\n",
    "#         lineEnd = point_list[y+1]\n",
    "#         # Creates line based on the start and end points previously specified\n",
    "#         line = QgsGeometry.fromPolylineXY([lineStart, lineEnd])\n",
    "#         # Create empty feature for line\n",
    "#         linef = QgsFeature()\n",
    "#         # Set geometry to previously created PolyLine\n",
    "#         linef.setGeometry(line)\n",
    "#         # Append attributes from dataframe\n",
    "#         # Since the Line will consist of 2 points, both points' attributes must be stored in the line\n",
    "#         linef.setAttributes([filter_dato['Transect'].iloc[y], \\\n",
    "#                  int(filter_dato['Point Number'].iloc[y]), \\\n",
    "#                  filter_dato['Subclass'].iloc[y], \\\n",
    "#                  filter_dato['Northing'].iloc[y].item(), \\\n",
    "#                  filter_dato['Easting'].iloc[y].item(), \\\n",
    "#                  filter_dato['Altitude'].iloc[y].item(), \\\n",
    "#                  filter_dato['Notes'].iloc[y], \\\n",
    "#                  filter_dato['Class'].iloc[y].item(), \\\n",
    "#                  filter_dato['Raw Subclass'].iloc[y], \\\n",
    "#                  filter_dato['Pre Angle'].iloc[y].item(), \\\n",
    "#                  filter_dato['Post Angle'].iloc[y].item(), \\\n",
    "#                  filter_dato['mu'].iloc[y].item(),  \\\n",
    "#                  filter_dato['Class mu'].iloc[y].item(), \\\n",
    "#                  filter_dato['Pre/Post'].iloc[y]])\n",
    "#         # if statement so a line is only written if it belongs to the same transect\n",
    "#         if filter_dato['Class'].iloc[y] == filter_dato['Class'].iloc[y+1] and transectCheck(y,filter_dato) == 1:\n",
    "#             writer.addFeature(linef)\n",
    "#             y += 1\n",
    "#         else:\n",
    "#             y += 1\n",
    "#     else: break\n",
    "# del(writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brett\\anaconda3\\envs\\CAFE\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: QgsVectorFileWriter constructor is deprecated\n"
     ]
    }
   ],
   "source": [
    "# Create mapping units based on subclasses\n",
    "\n",
    "# Create new shapefile for Points that do not create a line\n",
    "\n",
    "y = 0\n",
    "shape = gpd.read_file(XY_Points_outfile)\n",
    "muList2 = filter_dato['mu'].to_list()\n",
    "\n",
    "# for loop to write point for every mapping unit\n",
    "for i in muList2:\n",
    "    # Create if statement so you y is never > the length of your data set; this will end your script\n",
    "    if i == 1:\n",
    "            \n",
    "        # What file to write\n",
    "        file = mu_Folder + \"\\mu_\" + str(y) + \".shp\"\n",
    "        # Same as previous writer, except QgsWkbTypes. is Polygon\n",
    "        writer = QgsVectorFileWriter(file, 'UTF-8', layerFields, QgsWkbTypes.MultiPoint, \\\n",
    "                                QgsCoordinateReferenceSystem('EPSG:26919'), 'ESRI Shapefile')\n",
    "        poly1 = QgsGeometry.fromPointXY(point_list[y])\n",
    "        feat1 = QgsFeature()\n",
    "        feat1.setGeometry(poly1)\n",
    "        feat1.setAttributes([filter_dato['Transect'].iloc[y], \\\n",
    "                 int(filter_dato['Point Number'].iloc[y]), \\\n",
    "                 filter_dato['Subclass'].iloc[y], \\\n",
    "                 filter_dato['Northing'].iloc[y].item(), \\\n",
    "                 filter_dato['Easting'].iloc[y].item(), \\\n",
    "                 filter_dato['Altitude'].iloc[y].item(), \\\n",
    "                 filter_dato['Notes'].iloc[y], \\\n",
    "                 filter_dato['Class'].iloc[y].item(), \\\n",
    "                 filter_dato['Raw Subclass'].iloc[y], \\\n",
    "                 filter_dato['Pre Angle'].iloc[y].item(), \\\n",
    "                 filter_dato['Post Angle'].iloc[y].item(), \\\n",
    "                 filter_dato['mu'].iloc[y].item(),  \\\n",
    "                 filter_dato['Class mu'].iloc[y].item(), \\\n",
    "                 filter_dato['Pre/Post'].iloc[y]])\n",
    "        y += 1\n",
    "        writer.addFeature(feat1)\n",
    "    else: \n",
    "        y += 1\n",
    "del(writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of folders that contain newly created shapefiles to iterate through\n",
    "concat_list = [linesFolder, mu_Folder]\n",
    "n = 0\n",
    "\n",
    "for i in concat_list:\n",
    "    file = os.listdir(i)\n",
    "    path = [os.path.join(i, x) for x in file if \".shp\" in x]\n",
    "    gdf = gpd.GeoDataFrame(pd.concat([gpd.read_file(x) for x in path],\n",
    "                                    ignore_index=True), crs=gpd.read_file(path[0]).crs)\n",
    "    if n == 0: gdf.to_file(i + \"\\\\Lines_Comp\")\n",
    "    elif n == 1: gdf.to_file(i + \"\\\\Class_Lines_Comp\")\n",
    "    else: gdf.to_file(i + \"\\\\mu_Comp\")\n",
    "    \n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_fileList = [linesFolder + \"\\\\Lines_Comp\\\\Lines_Comp.shp\",\n",
    "                   mu_Folder + \"\\\\mu_Comp\\\\mu_Comp.shp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G:\\\\.shortcut-targets-by-id\\\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\\\SaltMUAS_share\\\\EPA Salt Marsh UAS Study\\\\Red River\\\\Jupyter_Working_Folder\\\\RR_13_Aug_2019\\\\Lines\\\\Lines_Comp\\\\Lines_Comp.shp',\n",
       " 'G:\\\\.shortcut-targets-by-id\\\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\\\SaltMUAS_share\\\\EPA Salt Marsh UAS Study\\\\Red River\\\\Jupyter_Working_Folder\\\\RR_13_Aug_2019\\\\mu\\\\mu_Comp\\\\mu_Comp.shp']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_fileList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buffer time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buffer lines\n",
    "\n",
    "# Assign empty folder to variable to write new file to\n",
    "linesBufferFolder = Buffer_Folder\n",
    "# Read in line shapefile of transects\n",
    "lines= gpd.read_file(concat_fileList[0])\n",
    "# Assign buffer and keep attributes\n",
    "lines['geometry'] = lines.buffer(1, cap_style=3)\n",
    "# Write new shapefile\n",
    "lines.to_file(linesBufferFolder + \"\\\\Lines_Buffer\")\n",
    "\n",
    "# # Buffer Class lines\n",
    "\n",
    "# # Assign empty folder to variable to write new file to\n",
    "# classlinesBufferFolder = Class_Buffer_Folder\n",
    "# # Read in line shapefile of transects\n",
    "# lines= gpd.read_file(concat_fileList[1])\n",
    "# # Assign buffer and keep attributes\n",
    "# lines['geometry'] = lines.buffer(1, cap_style=3)\n",
    "# # Write new shapefile\n",
    "# lines.to_file(classlinesBufferFolder + \"\\\\Class_Lines_Buffer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buffer the mapping units\n",
    "\n",
    "# Specify which folder to look in to buffer mu\n",
    "file = os.listdir(mu_Folder)\n",
    "\n",
    "# Assign empty folder to variable to write new file to\n",
    "muBufferFolder = mu_Buffer_Folder\n",
    "\n",
    "# Begin buffer by iterating through each mapping unit\n",
    "path = [os.path.join(mu_Folder, i) for i in file if \".shp\" in i]\n",
    "y = 0\n",
    "for i in path:\n",
    "    mus = gpd.read_file(path[y])\n",
    "    if mus['Pre/Post'][0] == \"post\": \n",
    "        mus['geometry'] = mus.buffer(1, cap_style=3).rotate(mus[\"Post Angle\"][0], origin='center')\n",
    "        mus.to_file(muBufferFolder + \"\\\\mu_\" + str(mus[\"PointNum\"][0]) + \"_Buffer.shp\")\n",
    "    else: \n",
    "        mus['geometry'] = mus.buffer(1, cap_style=3).rotate(mus[\"Pre Angle\"][0], origin='center')\n",
    "        mus.to_file(muBufferFolder + \"\\\\mu_\" + str(mus[\"PointNum\"][0]) + \"_Buffer.shp\")\n",
    "    y += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate mapping units\n",
    "\n",
    "# Specify which folder to look in to compile mu\n",
    "file = os.listdir(muBufferFolder)\n",
    "\n",
    "# Look for all files ending in \".shp\"\n",
    "path = [os.path.join(muBufferFolder, i) for i in file if \".shp\" in i]\n",
    "\n",
    "# Concatenate to file specified in last line of code\n",
    "gdf = gpd.GeoDataFrame(pd.concat([gpd.read_file(i) for i in path],\n",
    "                        ignore_index=True), crs=gpd.read_file(path[0]).crs)\n",
    "# Write to same folder + name of new folder to be created which will include the shapefile of compiled XY Points\n",
    "# Variable below is the suffix to add to linesFolder to specify folder to store compiled line files\n",
    "muCompSuff = \"\\\\mu_Comp\"\n",
    "gdf.to_file(muBufferFolder + muCompSuff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erase the Duplicate Overlapping Dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries needed for erase\n",
    "\n",
    "from itertools import combinations\n",
    "from shapely.geometry import LineString\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in transect polygons as GeoDataFrame\n",
    "\n",
    "polygdf = gpd.GeoDataFrame.from_file(linesBufferFolder + \"\\\\Lines_Buffer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use itertools to iterate through all polys within shapefile by combination\n",
    "\n",
    "for p1_idx, p2_idx in combinations(polygdf.geometry.index, 2):\n",
    "    if polygdf.geometry.loc[p1_idx].intersects(polygdf.geometry.loc[p2_idx]):\n",
    "        # Store intermediary results back to poly\n",
    "        polygdf.geometry.loc[p2_idx] -= polygdf.geometry.loc[p1_idx]\n",
    "# polygdf is now saved with the new geometry where it does not overlap itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview polygons using matplotlib\n",
    "polygdf.plot(alpha=0.75, cmap=\"tab10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "mugdf = gpd.GeoDataFrame.from_file(muBufferFolder + muCompSuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mu_idx in mugdf.geometry.index:\n",
    "    for p1_idx in polygdf.geometry.index:\n",
    "        if mugdf.geometry.loc[mu_idx].intersects(polygdf.geometry.loc[p1_idx]):\n",
    "            # Store intermediary results back to poly\n",
    "            polygdf.geometry.loc[p1_idx] -= mugdf.geometry.loc[mu_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erase overlapping mapping untis\n",
    "\n",
    "for p1_idx, p2_idx in combinations(mugdf.geometry.index, 2):\n",
    "    if mugdf.geometry.loc[p1_idx].intersects(mugdf.geometry.loc[p2_idx]):\n",
    "        # Store intermediary results back to poly\n",
    "        mugdf.geometry.loc[p2_idx] -= mugdf.geometry.loc[p1_idx]\n",
    "# mugdf is now saved with the new geometry where it does not overlap itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin Final File Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Path of Site in UAS Data Collection (and Year if Applicable) to Write Final Output --- \"G:\\.shortcut-targets-by-id\\0B6-MI-dco6FLWkZmTDZ4MFhRU1k\\SaltMUAS_share\\UAS Data Collection\\Red River\\2019\"\n",
      "Folder creation complete.\n"
     ]
    }
   ],
   "source": [
    "# Input Final Output Folder Path\n",
    "rootOut = input(\"Enter Path of Site in UAS Data Collection (and Year if Applicable) to Write Final Output --- \")\n",
    "rootOut = rootOut[1:-1]\n",
    "workingFinal = rootOut + \"\\\\Transects_Working\"\n",
    "transectFinal = rootOut + \"\\\\Transects\"\n",
    "\n",
    "# Create list of variables with folder paths stored\n",
    "finalfolderList = [workingFinal, transectFinal]\n",
    "\n",
    "# Iterate through folder list and create folder if it does not already exist\n",
    "for i in finalfolderList:\n",
    "    if not os.path.exists(i):\n",
    "        os.makedirs(i)\n",
    "        print(str(i) + \" created.\")\n",
    "print(\"Folder creation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify date in the name of the shapefile\n",
    "\n",
    "# Use previously defined workIn variable to name file\n",
    "outShape = workingFinal + r\"\\\\\" + workIn + \"_Transects_Final.shp\"\n",
    "outMu = workingFinal + r\"\\\\\" + workIn + \"_mu_Final.shp\"\n",
    "\n",
    "polygdf.to_file(outShape)\n",
    "mugdf.to_file(outMu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
